{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac002936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, json, math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4d00ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')   # Check wether gpu is available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ec84e",
   "metadata": {},
   "source": [
    "### The Mandelbrot set\n",
    "The Mandelbrot set is a two-dimensional set that is defined in the complex plane as the complex numbers $c$ for which the function $f_c(z) = z^2 + c $ does not diverge to infinity when iterated starting at $z=0$.\n",
    "\n",
    "Interesting properties:\n",
    "- A point c belongs to the Mandelbrot set iff $|z| \\leq 2$ for all $n \\geq 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eaf9f6",
   "metadata": {},
   "source": [
    "### Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5abc2422",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def model_grid_tiled(model, device, xlim, ylim, res, tile=(512, 512), amp=True):\n",
    "    model.eval()\n",
    "    W, H = res\n",
    "    tw, th = tile\n",
    "\n",
    "    xs = np.linspace(xlim[0], xlim[1], W, endpoint=False, dtype=np.float32)\n",
    "    ys = np.linspace(ylim[0], ylim[1], H, endpoint=False, dtype=np.float32)\n",
    "\n",
    "    out = np.empty((H, W), dtype=np.float32)\n",
    "\n",
    "    for y0 in range(0, H, th):\n",
    "        y1 = min(y0 + th, H)\n",
    "        Y = ys[y0:y1]\n",
    "\n",
    "        for x0 in range(0, W, tw):\n",
    "            x1 = min(x0 + tw, W)\n",
    "            X = xs[x0:x1]\n",
    "\n",
    "            XX, YY = np.meshgrid(X, Y)\n",
    "            grid = np.stack([XX.reshape(-1), YY.reshape(-1)], axis=1)\n",
    "\n",
    "            g = torch.from_numpy(grid).to(\n",
    "                device,\n",
    "                dtype=torch.float16 if (amp and device.type == \"cuda\") else torch.float32,\n",
    "                non_blocking=True\n",
    "            )\n",
    "\n",
    "            if amp and device.type == \"cuda\":\n",
    "                with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                    v = model(g).squeeze(1)\n",
    "            else:\n",
    "                v = model(g).squeeze(1)\n",
    "\n",
    "            out[y0:y1, x0:x1] = v.float().cpu().numpy().reshape((y1 - y0, x1 - x0))\n",
    "            del XX, YY, grid, g, v\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32f850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ylim_from_x(xlim, res, ycenter=0.0):\n",
    "    \"\"\"\n",
    "    Keep square pixels in complex plane by matching step size in x and y.\n",
    "    \"\"\"\n",
    "    W, H = res\n",
    "    step = (xlim[1] - xlim[0]) / W\n",
    "    y_half = step * H / 2\n",
    "    return (ycenter - y_half, ycenter + y_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad6b7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fractal_palette(name):\n",
    "    palettes = {\n",
    "        # ðŸ”¥ Cinematic fire (classic, hard to beat)\n",
    "        \"fire\": [\n",
    "            (0.02, 0.02, 0.05),\n",
    "            (0.10, 0.02, 0.20),\n",
    "            (0.40, 0.05, 0.30),\n",
    "            (0.80, 0.20, 0.10),\n",
    "            (0.98, 0.80, 0.30),\n",
    "        ],\n",
    "\n",
    "        # ðŸŒŒ Cosmic / nebula\n",
    "        \"cosmic\": [\n",
    "            (0.01, 0.01, 0.04),\n",
    "            (0.05, 0.02, 0.20),\n",
    "            (0.20, 0.10, 0.60),\n",
    "            (0.60, 0.40, 0.90),\n",
    "            (0.95, 0.85, 0.98),\n",
    "        ],\n",
    "\n",
    "        # ðŸŒŠ Deep ocean\n",
    "        \"ocean\": [\n",
    "            (0.01, 0.02, 0.05),\n",
    "            (0.02, 0.10, 0.20),\n",
    "            (0.05, 0.40, 0.50),\n",
    "            (0.30, 0.80, 0.70),\n",
    "            (0.90, 0.95, 0.85),\n",
    "        ],\n",
    "\n",
    "        # ðŸŒˆ Synthwave / neon\n",
    "        \"synthwave\": [\n",
    "            (0.02, 0.00, 0.08),\n",
    "            (0.20, 0.00, 0.40),\n",
    "            (0.60, 0.10, 0.80),\n",
    "            (0.90, 0.30, 0.60),\n",
    "            (1.00, 0.90, 0.30),\n",
    "        ],\n",
    "\n",
    "        # ðŸ–¤ Ink / poster\n",
    "        \"ink\": [\n",
    "            (0.00, 0.00, 0.00),\n",
    "            (0.10, 0.10, 0.10),\n",
    "            (0.40, 0.40, 0.40),\n",
    "            (0.85, 0.85, 0.85),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    return LinearSegmentedColormap.from_list(\n",
    "        f\"fract_{name}\", palettes[name], N=2048\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def glow(img, strength=0.25, radius=3, threshold=0.6):\n",
    "    \"\"\"\n",
    "    img: [0,1] float32\n",
    "    threshold: only values above this emit glow\n",
    "    \"\"\"\n",
    "    src = img.copy()\n",
    "\n",
    "    # mask bright regions only\n",
    "    mask = np.clip((src - threshold) / (1.0 - threshold), 0.0, 1.0)\n",
    "    glow_src = src * mask\n",
    "\n",
    "    out = glow_src\n",
    "    for _ in range(radius):\n",
    "        out = (\n",
    "            np.roll(out, 1, 0) + np.roll(out, -1, 0) +\n",
    "            np.roll(out, 1, 1) + np.roll(out, -1, 1) + out\n",
    "        ) / 5.0\n",
    "\n",
    "    return np.clip(img + strength * out, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98b67f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_heatmap_tiled(\n",
    "    model, device,\n",
    "    xlim=(-2.4, 1.0),\n",
    "    ycenter=0.0,\n",
    "    res=(3840, 2160),\n",
    "    tile=(512, 512),\n",
    "    fname=\"render.png\",\n",
    "    title=\"Model\",\n",
    "    amp=False,\n",
    "    gamma=0.85,\n",
    "    qlo=0.01,\n",
    "    qhi=0.99,\n",
    "    cmap_custom=\"synthwave\",\n",
    "):\n",
    "    ylim = compute_ylim_from_x(xlim, res, ycenter=ycenter)\n",
    "\n",
    "    # render logits (or raw regression output) in float32\n",
    "    pred = model_grid_tiled(model, device, xlim, ylim, res, tile=tile, amp=amp).astype(np.float32)\n",
    "\n",
    "    pred = 1.0 / (1.0 + np.exp(-pred))   # sigmoid -> [0,1]\n",
    "\n",
    "    # robust contrast to avoid flattening + avoid amplifying tiny noise too much\n",
    "    lo, hi = np.quantile(pred, [qlo, qhi])\n",
    "    pred = (pred - lo) / (hi - lo + 1e-8)\n",
    "    pred = np.clip(pred, 0.0, 1.0)\n",
    "\n",
    "    # mild gamma (too aggressive gamma makes grain visible)\n",
    "    pred = pred ** gamma\n",
    "\n",
    "    # add glow\n",
    "    pred_glow = glow(pred, strength=0.30, radius=4, threshold=0.5)\n",
    "\n",
    "    dpi = 300\n",
    "    figsize = (res[0] / dpi, res[1] / dpi)\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "\n",
    "    cmap=fractal_palette(cmap_custom)\n",
    "    ax.imshow(\n",
    "        pred_glow,\n",
    "        extent=[xlim[0], xlim[1], ylim[0], ylim[1]],\n",
    "        origin=\"lower\",\n",
    "        interpolation=\"none\",\n",
    "        aspect=\"equal\",\n",
    "        cmap=cmap,\n",
    "    )\n",
    "    ax.set_axis_off()\n",
    "    plt.subplots_adjust(0, 0, 1, 1, 0, 0)\n",
    "    fig.savefig(fname, dpi=dpi, bbox_inches=None, pad_inches=0)\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e2cde5",
   "metadata": {},
   "source": [
    "### Fourier Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "679ebaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierFeatures(nn.Module):\n",
    "    \"\"\"\n",
    "        Gaussian Fourier Features\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=2, num_feats=256, sigma=10.0):\n",
    "        super().__init__()\n",
    "        B = torch.randn(in_dim, num_feats) * sigma\n",
    "        self.register_buffer(\"B\", B)\n",
    "\n",
    "    def forward(self, x):\n",
    "        proj = 2 * np.pi * x @ self.B\n",
    "        return torch.cat([proj.sin(), proj.cos()], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df4f2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleGaussianFourierFeatures(nn.Module):\n",
    "    def __init__(self, in_dim=2, num_feats=512, sigmas=(2.0, 6.0, 10.0), seed=0):\n",
    "        super().__init__()\n",
    "        # split features across scales\n",
    "        k = len(sigmas)\n",
    "        per = [num_feats // k] * k\n",
    "        per[0] += num_feats - sum(per)\n",
    "\n",
    "        Bs = []\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed)\n",
    "        for s, m in zip(sigmas, per):\n",
    "            B = torch.randn(in_dim, m, generator=g) * s\n",
    "            Bs.append(B)\n",
    "\n",
    "        self.register_buffer(\"B\", torch.cat(Bs, dim=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        proj = (2 * torch.pi) * (x @ self.B)\n",
    "        return torch.cat([torch.sin(proj), torch.cos(proj)], dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454821ee",
   "metadata": {},
   "source": [
    "### Creating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c980cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_escape(x: float, y: float, max_iter: int = 1000) -> float:\n",
    "    c = complex(x, y)\n",
    "    z = 0j\n",
    "    for n in range(max_iter):\n",
    "        z = z*z + c\n",
    "        r2 = z.real*z.real + z.imag*z.imag\n",
    "        if r2 > 4.0:\n",
    "            r = math.sqrt(r2)\n",
    "            mu = n + 1 - math.log(math.log(r)) / math.log(2.0)  # smooth\n",
    "            # log-scale to spread small mu\n",
    "            v = math.log1p(mu) / math.log1p(max_iter)\n",
    "            return float(np.clip(v, 0.0, 1.0))\n",
    "    return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f52abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_uniform(n, xlim, ylim, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    xs = rng.uniform(xlim[0], xlim[1], n)\n",
    "    ys = rng.uniform(ylim[0], ylim[1], n)\n",
    "    return np.stack([xs, ys], axis=1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f2da32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_boundary_biased_dataset(\n",
    "    n_total=800_000,\n",
    "    frac_boundary=0.7,\n",
    "    xlim=(-2.4, 1.0),\n",
    "    res_for_ylim=(3840, 2160),\n",
    "    ycenter=0.0,\n",
    "    max_iter=1000,\n",
    "    band=(0.05, 0.98),\n",
    "    seed=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Stable alternative to loss-reweighting:\n",
    "    - Mix of uniform samples + boundary-band samples.\n",
    "    - 'band' selects points with target in (low, high), which tends to concentrate near boundary.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    ylim = compute_ylim_from_x(xlim, res_for_ylim, ycenter=ycenter)\n",
    "\n",
    "    n_boundary = int(n_total * frac_boundary)\n",
    "    n_uniform  = n_total - n_boundary\n",
    "\n",
    "    # Uniform set\n",
    "    Xu = sample_uniform(n_uniform, xlim, ylim, seed=seed)\n",
    "\n",
    "    # Boundary pool: oversample, then filter by band\n",
    "    pool_factor = 20\n",
    "    pool = sample_uniform(n_boundary * pool_factor, xlim, ylim, seed=seed + 1)\n",
    "\n",
    "    yp = np.empty((pool.shape[0],), dtype=np.float32)\n",
    "    for i, (x, y) in enumerate(pool):\n",
    "        yp[i] = smooth_escape(float(x), float(y), max_iter=max_iter)\n",
    "\n",
    "    mask = (yp > band[0]) & (yp < band[1])\n",
    "    Xb = pool[mask]\n",
    "    yb = yp[mask]\n",
    "\n",
    "    if len(Xb) < n_boundary:\n",
    "        # If band too strict, relax it automatically\n",
    "        keep = min(len(Xb), n_boundary)\n",
    "        print(f\"[warn] Boundary band too strict; got {len(Xb)} boundary points, using {keep}.\")\n",
    "        Xb = Xb[:keep]\n",
    "        yb = yb[:keep]\n",
    "        n_boundary = keep\n",
    "        n_uniform = n_total - n_boundary\n",
    "        Xu = sample_uniform(n_uniform, xlim, ylim, seed=seed)\n",
    "\n",
    "    else:\n",
    "        Xb = Xb[:n_boundary]\n",
    "        yb = yb[:n_boundary]\n",
    "\n",
    "    yu = np.empty((Xu.shape[0],), dtype=np.float32)\n",
    "    for i, (x, y) in enumerate(Xu):\n",
    "        yu[i] = smooth_escape(float(x), float(y), max_iter=max_iter)\n",
    "\n",
    "    X = np.concatenate([Xu, Xb], axis=0).astype(np.float32)\n",
    "    y = np.concatenate([yu, yb], axis=0).astype(np.float32)\n",
    "\n",
    "    # Shuffle once\n",
    "    perm = rng.permutation(X.shape[0])\n",
    "    return X[perm], y[perm], ylim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84773515",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexedTensorDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # X: numpy (N,2), y: numpy (N,)\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aa35c8",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79db95bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim: int, act: str = \"silu\", dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        activation = nn.ReLU if act.lower() == \"relu\" else nn.SiLU\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(dim)\n",
    "        self.fc1 = nn.Linear(dim, dim)\n",
    "\n",
    "        self.ln2 = nn.LayerNorm(dim)\n",
    "        self.fc2 = nn.Linear(dim, dim)\n",
    "\n",
    "        self.act = activation()\n",
    "        self.drop = nn.Dropout(dropout) if dropout and dropout > 0 else nn.Identity()\n",
    "\n",
    "        # small init for the last layer to start near-identity\n",
    "        nn.init.zeros_(self.fc2.weight)\n",
    "        nn.init.zeros_(self.fc2.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.ln1(x)\n",
    "        h = self.act(self.fc1(h))\n",
    "        h = self.drop(h)\n",
    "        h = self.ln2(h)\n",
    "        h = self.fc2(h)\n",
    "        return x + h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcd2d2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPFourierRes(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_feats=256,\n",
    "        sigma=5.0,\n",
    "        hidden_dim=256,\n",
    "        num_blocks=8,\n",
    "        act=\"silu\",\n",
    "        dropout=0.0,\n",
    "        out_dim=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ff = MultiScaleGaussianFourierFeatures(\n",
    "            2,\n",
    "            num_feats=num_feats,\n",
    "            sigmas=(2.0, 6.0, sigma),\n",
    "            seed=0\n",
    "        )\n",
    "\n",
    "        self.in_proj = nn.Linear(2 * num_feats, hidden_dim)\n",
    "\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            ResidualBlock(hidden_dim, act=act, dropout=dropout)\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "        self.out_ln = nn.LayerNorm(hidden_dim)\n",
    "        activation = nn.ReLU if act.lower() == \"relu\" else nn.SiLU\n",
    "        self.out_act = activation()\n",
    "\n",
    "        self.out_proj = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ff(x)\n",
    "        x = self.in_proj(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.out_act(self.out_ln(x))\n",
    "        return self.out_proj(x)  # still no sigmoid during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eda3df",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b1d6bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_loss(model, loader, device, criterion):\n",
    "    model.eval()\n",
    "    tot = 0.0\n",
    "    n = 0\n",
    "    for Xb, yb, _ in loader:\n",
    "        Xb = Xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        pred = model(Xb)\n",
    "        loss = criterion(pred, yb).mean()\n",
    "        tot += float(loss.item()) * Xb.size(0)\n",
    "        n += Xb.size(0)\n",
    "    return tot / max(1, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3667614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    run_dir,\n",
    "    epochs=50,\n",
    "    batch_size=4096,\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-6,\n",
    "    grad_clip=1.0,\n",
    "    amp=True,\n",
    "    render_every=10,\n",
    "    render_res=(1920, 1080),\n",
    "    xlim=(-2.4, 1.0),\n",
    "    ycenter=0.0,\n",
    "    tile=(512, 512),\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    # SmoothL1 is very stable for this.\n",
    "    criterion = nn.SmoothL1Loss(reduction=\"none\")\n",
    "\n",
    "    opt = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(amp and device.type == \"cuda\"))\n",
    "\n",
    "    metrics_path = run_dir / \"metrics.csv\"\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        f.write(\"epoch,train_loss,val_loss\\n\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        tot = 0.0\n",
    "        n = 0\n",
    "\n",
    "        for Xb, yb, _ in train_loader:\n",
    "            Xb = Xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=(amp and device.type == \"cuda\")):\n",
    "                pred = model(Xb)\n",
    "                loss = criterion(pred, yb).mean()\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if grad_clip is not None:\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "\n",
    "            tot += float(loss.item()) * Xb.size(0)\n",
    "            n += Xb.size(0)\n",
    "\n",
    "        train_loss = tot / max(1, n)\n",
    "        val_loss = eval_loss(model, val_loader, device, criterion)\n",
    "\n",
    "        scheduler.step()\n",
    "        with open(metrics_path, \"a\") as f:\n",
    "            f.write(f\"{epoch},{train_loss:.8f},{val_loss:.8f}\\n\")\n",
    "\n",
    "        print(f\"Epoch {epoch:03d} | train {train_loss:.6f} | val {val_loss:.6f}\")\n",
    "\n",
    "        # checkpoint\n",
    "        if epoch == epochs or (epoch % render_every == 0):\n",
    "            ckpt_path = run_dir / \"ckpt\" / f\"model_epoch_{epoch:03d}.pt\"\n",
    "            torch.save(model.state_dict(), ckpt_path)\n",
    "\n",
    "            # render a preview image\n",
    "            out_img = run_dir / \"images\" / f\"render_epoch_{epoch:03d}.png\"\n",
    "            plot_model_heatmap_tiled(\n",
    "                model, device,\n",
    "                xlim=xlim, ycenter=ycenter, res=render_res, tile=tile,\n",
    "                fname=str(out_img),\n",
    "                title=f\"Model (epoch {epoch})\",\n",
    "                amp=amp\n",
    "            )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3404f",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "269cf6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_run_dir(base=\"runs\", tag=\"\"):\n",
    "    \"\"\" Make directory to track experiment \"\"\"\n",
    "    ts = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    name = ts + (f\"_{tag}\" if tag else \"\")\n",
    "    run_dir = Path(base) / name\n",
    "    run_dir.mkdir(parents=True, exist_ok=False)\n",
    "    (run_dir / \"images\").mkdir(exist_ok=True)\n",
    "    (run_dir / \"ckpt\").mkdir(exist_ok=True)\n",
    "    return run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc0f1bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run dir: runs/2025-12-31_17-40-22_mandelbrot_competitive\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRun dir:\u001b[39m\u001b[33m\"\u001b[39m, run_dir)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Build dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m X, y, ylim = \u001b[43mbuild_boundary_biased_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_total\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset_n_total\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrac_boundary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset_frac_boundary\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxlim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mxlim\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mres_for_ylim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mres_for_ylim\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mycenter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mycenter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_iter_labels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mband\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mboundary_band\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33my stats:\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     52\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(y.min()),\n\u001b[32m     53\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(y.max()),\n\u001b[32m     54\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(y.mean()),\n\u001b[32m     55\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mp50\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(np.quantile(y, \u001b[32m0.50\u001b[39m)),\n\u001b[32m     56\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mp99\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(np.quantile(y, \u001b[32m0.99\u001b[39m)))\n\u001b[32m     58\u001b[39m X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=\u001b[32m0.15\u001b[39m, random_state=cfg[\u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m], shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mbuild_boundary_biased_dataset\u001b[39m\u001b[34m(n_total, frac_boundary, xlim, res_for_ylim, ycenter, max_iter, band, seed)\u001b[39m\n\u001b[32m     29\u001b[39m yp = np.empty((pool.shape[\u001b[32m0\u001b[39m],), dtype=np.float32)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pool):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     yp[i] = \u001b[43msmooth_escape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m mask = (yp > band[\u001b[32m0\u001b[39m]) & (yp < band[\u001b[32m1\u001b[39m])\n\u001b[32m     34\u001b[39m Xb = pool[mask]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36msmooth_escape\u001b[39m\u001b[34m(x, y, max_iter)\u001b[39m\n\u001b[32m      5\u001b[39m z = z*z + c\n\u001b[32m      6\u001b[39m r2 = z.real*z.real + z.imag*z.imag\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r2 > \u001b[32m4.0\u001b[39m:\n\u001b[32m      8\u001b[39m     r = math.sqrt(r2)\n\u001b[32m      9\u001b[39m     mu = n + \u001b[32m1\u001b[39m - math.log(math.log(r)) / math.log(\u001b[32m2.0\u001b[39m)  \u001b[38;5;66;03m# smooth\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    \"xlim\": (-2.4, 1.0),\n",
    "    \"res_for_ylim\": (3840, 2160),\n",
    "    \"ycenter\": 0.0,\n",
    "    \"max_iter_labels\": 1000,\n",
    "\n",
    "    \"dataset_n_total\": 1000000,\n",
    "    \"dataset_frac_boundary\": 0.7,\n",
    "    \"boundary_band\": (0.35, 0.95),\n",
    "    \"seed\": 0,\n",
    "\n",
    "    \"model_num_feats\": 512,\n",
    "    \"model_sigma\": 10.0,\n",
    "    \"model_hidden_dim\": 512,\n",
    "    \"model_hidden_layers\": 20,\n",
    "    \"model_act\": \"silu\",\n",
    "\n",
    "    \"train_epochs\": 100,\n",
    "    \"train_batch_size\": 4096,\n",
    "    \"train_lr\": 3e-4,\n",
    "    \"train_weight_decay\": 1e-6,\n",
    "    \"train_grad_clip\": 1.0,\n",
    "    \"train_amp\": True,\n",
    "\n",
    "    \"preview_every\": 1,\n",
    "    \"preview_res\": (1920, 1080),\n",
    "    \"preview_tile\": (512, 512),\n",
    "\n",
    "    \"final_res\": (3840, 2160),\n",
    "    \"final_tile\": (512, 512),\n",
    "}\n",
    "\n",
    "run_dir = make_run_dir(tag=\"mandelbrot_competitive\")\n",
    "with open(run_dir / \"config.json\", \"w\") as f:\n",
    "    json.dump(cfg, f, indent=2)\n",
    "\n",
    "print(\"Run dir:\", run_dir)\n",
    "\n",
    "# Build dataset\n",
    "X, y, ylim = build_boundary_biased_dataset(\n",
    "    n_total=cfg[\"dataset_n_total\"],\n",
    "    frac_boundary=cfg[\"dataset_frac_boundary\"],\n",
    "    xlim=cfg[\"xlim\"],\n",
    "    res_for_ylim=cfg[\"res_for_ylim\"],\n",
    "    ycenter=cfg[\"ycenter\"],\n",
    "    max_iter=cfg[\"max_iter_labels\"],\n",
    "    band=cfg[\"boundary_band\"],\n",
    "    seed=cfg[\"seed\"],\n",
    ")\n",
    "\n",
    "print(\"y stats:\",\n",
    "        \"min\", float(y.min()),\n",
    "        \"max\", float(y.max()),\n",
    "        \"mean\", float(y.mean()),\n",
    "        \"p50\", float(np.quantile(y, 0.50)),\n",
    "        \"p99\", float(np.quantile(y, 0.99)))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=cfg[\"seed\"], shuffle=True)\n",
    "\n",
    "train_ds = IndexedTensorDataset(X_train, y_train)\n",
    "val_ds   = IndexedTensorDataset(X_val,   y_val)\n",
    "\n",
    "# Model\n",
    "model = MLPFourierRes(\n",
    "    num_feats=cfg[\"model_num_feats\"],\n",
    "    sigma=cfg[\"model_sigma\"],\n",
    "    hidden_dim=cfg[\"model_hidden_dim\"],\n",
    "    num_blocks=cfg[\"model_hidden_layers\"],\n",
    "    act=cfg[\"model_act\"],\n",
    "    dropout=0.0,\n",
    ")\n",
    "\n",
    "# Train\n",
    "model = train_model(\n",
    "    model,\n",
    "    train_ds,\n",
    "    val_ds,\n",
    "    run_dir=run_dir,\n",
    "    epochs=cfg[\"train_epochs\"],\n",
    "    batch_size=cfg[\"train_batch_size\"],\n",
    "    lr=cfg[\"train_lr\"],\n",
    "    weight_decay=cfg[\"train_weight_decay\"],\n",
    "    grad_clip=cfg[\"train_grad_clip\"],\n",
    "    amp=cfg[\"train_amp\"],\n",
    "    render_every=cfg[\"preview_every\"],\n",
    "    render_res=cfg[\"preview_res\"],\n",
    "    xlim=cfg[\"xlim\"],\n",
    "    ycenter=cfg[\"ycenter\"],\n",
    "    tile=cfg[\"preview_tile\"],\n",
    ")\n",
    "\n",
    "# Final 4K render\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "final_path = run_dir / \"images\" / \"final_4k.png\"\n",
    "plot_model_heatmap_tiled(\n",
    "    model, device,\n",
    "    xlim=cfg[\"xlim\"],\n",
    "    ycenter=cfg[\"ycenter\"],\n",
    "    res=cfg[\"final_res\"],\n",
    "    tile=cfg[\"final_tile\"],\n",
    "    fname=str(final_path),\n",
    "    title=\"Final 4K Model Render\",\n",
    "    amp=cfg[\"train_amp\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3244ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"models/fourier_mlp_final.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
